{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa86fd6-540f-468b-a1e7-c62495a7e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced GAN Training on Jetstream2\n",
    "## CS650 - Neural Networks & Deep Learning\n",
    "### Student: Matthew Walker 901835718\n",
    "\n",
    "#This notebook implements an enhanced Generative Adversarial Network with:\n",
    "#Real-time training visualization\n",
    "#Loss curves and metrics tracking\n",
    "#Generated image evolution grid\n",
    "#GPU utilization monitoring\n",
    "#Interactive sample generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d821dc9b-9b9d-4599-a3c5-2e239dc4e97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import gridspec\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, display, HTML\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "print(\"? All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aab9f38d-5ab6-4bf4-aca5-79d3f3cbc0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Student: Matthew Walker\n",
      "ID: 901835710\n",
      "Course: CS650\n",
      "Task: Jetstream2 GPU Training Task\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "STUDENT_NAME = \"Matthew Walker\"\n",
    "STUDENT_ID = \"901835710\"\n",
    "COURSE = \"CS650\"\n",
    "TASK = \"Jetstream2 GPU Training Task\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Student: {STUDENT_NAME}\")\n",
    "print(f\"ID: {STUDENT_ID}\")\n",
    "print(f\"Course: {COURSE}\")\n",
    "print(f\"Task: {TASK}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95723081-ee66-47c3-9db6-0e390b170c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GPU CONFIGURATION\n",
      "============================================================\n",
      "Device: cuda\n",
      "GPU Name: NVIDIA A100-SXM4-40GB\n",
      "GPU Memory: 42.41 GB\n",
      "CUDA Version: 12.4\n",
      "PyTorch Version: 2.6.0+cu124\n",
      "? GPU is available and will be used for training\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# GPU AVAILABILITY CHECK\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(\"? GPU is available and will be used for training\")\n",
    "else:\n",
    "    print(\"? WARNING: GPU not available, using CPU (training will be slower)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04011438-0bc9-4a4b-abda-56ba7b421520",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# DATASET PREPARATION\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m transform = \u001b[43mtransforms\u001b[49m.Compose([\n\u001b[32m      3\u001b[39m     transforms.ToTensor(),\n\u001b[32m      4\u001b[39m     transforms.Normalize([\u001b[32m0.5\u001b[39m], [\u001b[32m0.5\u001b[39m])  \u001b[38;5;66;03m# Scale to [-1, 1]\u001b[39;00m\n\u001b[32m      5\u001b[39m ])\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDownloading MNIST dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m dataset = datasets.MNIST(root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, train=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=transform, download=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "# DATASET PREPARATION\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Scale to [-1, 1]\n",
    "])\n",
    "\n",
    "print(\"Downloading MNIST dataset...\")\n",
    "dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "print(f\"? Dataset loaded: {len(dataset)} training images\")\n",
    "print(f\"? Batch size: 128\")\n",
    "print(f\"? Number of batches: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a31d6a-1078-4990-91e6-1d87089dbbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE REAL TRAINING DATA\n",
    "def show_images(images, title=\"Images\"):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.imshow(np.transpose(make_grid(images[:64], padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Show some real images\n",
    "real_batch = next(iter(dataloader))[0][:64]\n",
    "show_images(real_batch, \"Sample Real MNIST Digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba78aa1-8905-44bb-8655-04505aea9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# GENERATOR NETWORK\n",
    "# ============================================\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_dim=28*28):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Linear(1024, img_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "print(\"? Generator architecture defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca1a70-80e5-4d2e-b54d-d55ec62dbbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DISCRIMINATOR NETWORK\n",
    "# ============================================\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=28*28):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_dim, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "print(\"? Discriminator architecture defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57b7a1-a0f7-4d6b-8a76-162e604eaa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# MODEL INITIALIZATION\n",
    "# ============================================\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Count parameters\n",
    "g_params = sum(p.numel() for p in generator.parameters())\n",
    "d_params = sum(p.numel() for p in discriminator.parameters())\n",
    "\n",
    "print(f\"Generator Parameters: {g_params:,}\")\n",
    "print(f\"Discriminator Parameters: {d_params:,}\")\n",
    "print(f\"Total Parameters: {g_params + d_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b3765-2842-42bd-b9cc-e54d64344bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TRAINING CONFIGURATION\n",
    "# ============================================\n",
    "criterion = nn.BCELoss()\n",
    "optim_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optim_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "z_dim = 100\n",
    "epochs = 30\n",
    "save_interval = 5  # Save images every N epochs\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"samples\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# Fixed noise for consistent visualization\n",
    "fixed_noise = torch.randn(64, z_dim).to(device)\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Epochs: {epochs}\")\n",
    "print(f\"  Learning Rate: 0.0002\")\n",
    "print(f\"  Latent Dimension: {z_dim}\")\n",
    "print(f\"  Optimizer: Adam (beta1=0.5, beta2=0.999)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c0728-1499-46be-b253-e5e8749f1ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# VISUALIZATION UTILITIES\n",
    "# ============================================\n",
    "def plot_training_progress(g_losses, d_losses, epoch, total_epochs):\n",
    "    \"\"\"Create a comprehensive training visualization\"\"\"\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "    \n",
    "    # Loss curves\n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    ax1.plot(g_losses, label='Generator Loss', color='#2ecc71', linewidth=2)\n",
    "    ax1.plot(d_losses, label='Discriminator Loss', color='#e74c3c', linewidth=2)\n",
    "    ax1.set_xlabel('Batch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title(f'Training Progress - Epoch {epoch}/{total_epochs}', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Current metrics\n",
    "    ax2 = plt.subplot(gs[1])\n",
    "    ax2.axis('off')\n",
    "    metrics_text = f\"\"\"\\nCURRENT METRICS\\n\\n\n",
    "Epoch: {epoch}/{total_epochs}\\n\n",
    "Progress: {100*epoch/total_epochs:.1f}%\\n\\n\n",
    "\\nLatest Losses:\\n\n",
    "  Generator: {g_losses[-1]:.4f}\\n\n",
    "  Discriminator: {d_losses[-1]:.4f}\\n\\n\n",
    "\\nAvg (Last 10):\\n\n",
    "  Generator: {np.mean(g_losses[-10:]):.4f}\\n\n",
    "  Discriminator: {np.mean(d_losses[-10:]):.4f}\n",
    "    \"\"\"\n",
    "    ax2.text(0.1, 0.5, metrics_text, fontsize=11, verticalalignment='center',\n",
    "             family='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def generate_and_display(generator, fixed_noise, epoch):\n",
    "    \"\"\"Generate and display fake images\"\"\"\n",
    "    with torch.no_grad():\n",
    "        fake = generator(fixed_noise).view(-1, 1, 28, 28)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Generated Images - Epoch {epoch}\", fontsize=16, fontweight='bold')\n",
    "    plt.imshow(np.transpose(make_grid(fake.cpu(), padding=2, normalize=True), (1, 2, 0)))\n",
    "    return fig\n",
    "\n",
    "print(\"? Visualization utilities loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2c732-1e89-4c01-9eda-7b88c380cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# MAIN TRAINING LOOP WITH LIVE VISUALIZATION\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"STARTING TRAINING - {STUDENT_NAME} (ID: {STUDENT_ID})\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_g_loss = 0\n",
    "    epoch_d_loss = 0\n",
    "    \n",
    "    for batch_idx, (real_imgs, _) in enumerate(dataloader):\n",
    "        real_imgs = real_imgs.view(-1, 28*28).to(device)\n",
    "        batch_size = real_imgs.size(0)\n",
    "\n",
    "        # ============================================\n",
    "        # TRAIN DISCRIMINATOR\n",
    "        # ============================================\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake_imgs = generator(z).detach()\n",
    "        \n",
    "        d_loss_real = criterion(discriminator(real_imgs), torch.ones(batch_size, 1).to(device))\n",
    "        d_loss_fake = criterion(discriminator(fake_imgs), torch.zeros(batch_size, 1).to(device))\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        optim_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optim_D.step()\n",
    "\n",
    "        # ============================================\n",
    "        # TRAIN GENERATOR\n",
    "        # ============================================\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "        g_loss = criterion(discriminator(fake_imgs), torch.ones(batch_size, 1).to(device))\n",
    "\n",
    "        optim_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optim_G.step()\n",
    "\n",
    "        # Track losses\n",
    "        g_losses.append(g_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "        epoch_g_loss += g_loss.item()\n",
    "        epoch_d_loss += d_loss.item()\n",
    "\n",
    "    # ============================================\n",
    "    # EPOCH SUMMARY AND VISUALIZATION\n",
    "    # ============================================\n",
    "    avg_g_loss = epoch_g_loss / len(dataloader)\n",
    "    avg_d_loss = epoch_d_loss / len(dataloader)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"EPOCH [{epoch + 1}/{epochs}] COMPLETED\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Generator Loss:     {avg_g_loss:.4f}\")\n",
    "    print(f\"Discriminator Loss: {avg_d_loss:.4f}\")\n",
    "    print(f\"Time Elapsed:       {elapsed/60:.2f} minutes\")\n",
    "    print(f\"ETA:                {(elapsed/max(epoch, 1))*(epochs-epoch-1)/60:.2f} minutes\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plot_training_progress(g_losses, d_losses, epoch + 1, epochs)\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate and show fake images\n",
    "    if (epoch + 1) % save_interval == 0 or epoch == 0 or epoch == epochs - 1:\n",
    "        fig = generate_and_display(generator, fixed_noise, epoch + 1)\n",
    "        plt.show()\n",
    "        \n",
    "        # Save images\n",
    "        with torch.no_grad():\n",
    "            fake = generator(fixed_noise).view(-1, 1, 28, 28)\n",
    "            save_image(fake, f\"samples/fake_epoch_{epoch+1:03d}.png\", normalize=True)\n",
    "        \n",
    "        print(f\"? Saved generated images to samples/fake_epoch_{epoch+1:03d}.png\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Time: {(time.time() - start_time)/60:.2f} minutes\")\n",
    "print(f\"Final Generator Loss: {g_losses[-1]:.4f}\")\n",
    "print(f\"Final Discriminator Loss: {d_losses[-1]:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907d7b3-71f1-4554-a847-90946e1a724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SAVE TRAINED MODELS\n",
    "# ============================================\n",
    "torch.save({\n",
    "    'epoch': epochs,\n",
    "    'generator_state_dict': generator.state_dict(),\n",
    "    'discriminator_state_dict': discriminator.state_dict(),\n",
    "    'optim_G_state_dict': optim_G.state_dict(),\n",
    "    'optim_D_state_dict': optim_D.state_dict(),\n",
    "    'g_losses': g_losses,\n",
    "    'd_losses': d_losses,\n",
    "    'student_name': STUDENT_NAME,\n",
    "    'student_id': STUDENT_ID\n",
    "}, 'checkpoints/gan_final_checkpoint.pth')\n",
    "\n",
    "print(\"? Models saved to checkpoints/gan_final_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7190e24-1987-41b6-b5f5-c5ba9e0a878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FINAL TRAINING VISUALIZATION\n",
    "# ============================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Complete loss curves\n",
    "axes[0].plot(g_losses, label='Generator', alpha=0.7, color='#2ecc71')\n",
    "axes[0].plot(d_losses, label='Discriminator', alpha=0.7, color='#e74c3c')\n",
    "axes[0].set_xlabel('Iteration', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Complete Training Loss Curves', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Smoothed losses (moving average)\n",
    "window = 50\n",
    "g_smooth = np.convolve(g_losses, np.ones(window)/window, mode='valid')\n",
    "d_smooth = np.convolve(d_losses, np.ones(window)/window, mode='valid')\n",
    "axes[1].plot(g_smooth, label='Generator (smoothed)', color='#27ae60', linewidth=2)\n",
    "axes[1].plot(d_smooth, label='Discriminator (smoothed)', color='#c0392b', linewidth=2)\n",
    "axes[1].set_xlabel('Iteration', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].set_title(f'Smoothed Training Loss (window={window})', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('samples/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"? Final training curves saved to samples/training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a5d6a3-5bff-454c-9d80-4d6828b569fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# INTERACTIVE: GENERATE NEW SAMPLES\n",
    "# ============================================\n",
    "def generate_samples(n_samples=64):\n",
    "    \"\"\"Generate new samples from the trained generator\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(n_samples, z_dim).to(device)\n",
    "        fake_imgs = generator(z).view(-1, 1, 28, 28)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Newly Generated Samples (n={n_samples})\", fontsize=16, fontweight='bold')\n",
    "    plt.imshow(np.transpose(make_grid(fake_imgs.cpu(), padding=2, normalize=True), (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    return fake_imgs\n",
    "\n",
    "# Generate new samples\n",
    "print(\"Generating new samples from trained generator...\")\n",
    "new_samples = generate_samples(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21283b4c-0890-4d5b-b0dd-2c041a4a31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EVOLUTION GRID: Show progression over epochs\n",
    "# ============================================\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "sample_files = sorted(glob.glob('samples/fake_epoch_*.png'))\n",
    "\n",
    "if len(sample_files) > 0:\n",
    "    n_display = min(6, len(sample_files))\n",
    "    indices = np.linspace(0, len(sample_files)-1, n_display, dtype=int)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, i in enumerate(indices):\n",
    "        if idx < len(axes):\n",
    "            img = Image.open(sample_files[i])\n",
    "            epoch_num = int(sample_files[i].split('_')[-1].split('.')[0])\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].axis('off')\n",
    "            axes[idx].set_title(f'Epoch {epoch_num}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_display, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('GAN Training Evolution', fontsize=18, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('samples/training_evolution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"? Training evolution grid saved to samples/training_evolution.png\")\n",
    "else:\n",
    "    print(\"No sample images found in samples/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf2216-39f1-4a39-91b0-a650bd82f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# REAL VS FAKE COMPARISON\n",
    "# ============================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Real images\n",
    "real_batch = next(iter(dataloader))[0][:64]\n",
    "axes[0].imshow(np.transpose(make_grid(real_batch, padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Real MNIST Digits', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Generated images\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(64, z_dim).to(device)\n",
    "    fake_batch = generator(z).view(-1, 1, 28, 28)\n",
    "axes[1].imshow(np.transpose(make_grid(fake_batch.cpu(), padding=2, normalize=True), (1, 2, 0)))\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Generated Digits', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Real vs Generated Comparison', fontsize=18, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('samples/real_vs_fake.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"? Comparison saved to samples/real_vs_fake.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e989e6-2ad7-451c-80ea-dc0df90a2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TRAINING SUMMARY\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Student: {STUDENT_NAME}\")\n",
    "print(f\"ID: {STUDENT_ID}\")\n",
    "print(f\"Course: {COURSE}\")\n",
    "print(f\"Task: {TASK}\")\n",
    "print(f\"\\nDevice Used: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"\\nTotal Epochs: {epochs}\")\n",
    "print(f\"Total Training Time: {(time.time() - start_time)/60:.2f} minutes\")\n",
    "print(f\"\\nFinal Losses:\")\n",
    "print(f\"  Generator: {g_losses[-1]:.4f}\")\n",
    "print(f\"  Discriminator: {d_losses[-1]:.4f}\")\n",
    "print(f\"\\nOutput Files:\")\n",
    "print(f\"  ? Generated samples: samples/\")\n",
    "print(f\"  ? Training curves: samples/training_curves.png\")\n",
    "print(f\"  ? Evolution grid: samples/training_evolution.png\")\n",
    "print(f\"  ? Model checkpoint: checkpoints/gan_final_checkpoint.pth\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n?? SUCCESS! GAN training completed on Jetstream2 GPU\")\n",
    "print(\"\\nThis notebook demonstrates:\")\n",
    "print(\"  ? GPU-accelerated deep learning on Jetstream2\")\n",
    "print(\"  ? GAN architecture implementation\")\n",
    "print(\"  ? Real-time training visualization\")\n",
    "print(\"  ? Loss tracking and model checkpointing\")\n",
    "print(\"  ? Generated sample quality assessment\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
