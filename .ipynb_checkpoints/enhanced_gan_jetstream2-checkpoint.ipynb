{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Enhanced GAN Training on Jetstream2\n",
    "## CS650 - Neural Networks & Deep Learning\n",
    "### Student: Matthew [Your ID Here]\n",
    "---\n",
    "This notebook implements an enhanced Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "student_info",
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_NAME = \"Matthew Walker\"\n",
    "STUDENT_ID = \"901635710\"\n",
    "COURSE = \"CS650\"\n",
    "TASK = \"Jetstream2 GPU Training Task\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Student: {STUDENT_NAME}\")\n",
    "print(f\"ID: {STUDENT_ID}\")\n",
    "print(f\"Course: {COURSE}\")\n",
    "print(f\"Task: {TASK}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpu_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(\"✓ GPU is available and will be used for training\")\n",
    "else:\n",
    "    print(\"⚠ WARNING: GPU not available\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "print(f\"✓ Dataset loaded: {len(dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "models",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_dim=28*28):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256), nn.BatchNorm1d(256), nn.ReLU(True),\n",
    "            nn.Linear(256, 512), nn.BatchNorm1d(512), nn.ReLU(True),\n",
    "            nn.Linear(512, 1024), nn.BatchNorm1d(1024), nn.ReLU(True),\n",
    "            nn.Linear(1024, img_dim), nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=28*28):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_dim, 1024), nn.LeakyReLU(0.2), nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512), nn.LeakyReLU(0.2), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256), nn.LeakyReLU(0.2), nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "print(\"✓ Models initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optim_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optim_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "z_dim = 100\n",
    "epochs = 30\n",
    "os.makedirs(\"samples\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "fixed_noise = torch.randn(64, z_dim).to(device)\n",
    "print(f\"✓ Training config: {epochs} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"STARTING TRAINING - {STUDENT_NAME} (ID: {STUDENT_ID})\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for real_imgs, _ in dataloader:\n",
    "        real_imgs = real_imgs.view(-1, 28*28).to(device)\n",
    "        batch_size = real_imgs.size(0)\n",
    "\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake_imgs = generator(z).detach()\n",
    "        d_loss_real = criterion(discriminator(real_imgs), torch.ones(batch_size, 1).to(device))\n",
    "        d_loss_fake = criterion(discriminator(fake_imgs), torch.zeros(batch_size, 1).to(device))\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        optim_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optim_D.step()\n",
    "\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "        g_loss = criterion(discriminator(fake_imgs), torch.ones(batch_size, 1).to(device))\n",
    "        optim_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optim_G.step()\n",
    "\n",
    "        g_losses.append(g_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | G Loss: {g_loss.item():.4f} | D Loss: {d_loss.item():.4f}\")\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake = generator(fixed_noise).view(-1, 1, 28, 28)\n",
    "            save_image(fake, f\"samples/fake_epoch_{epoch+1:03d}.png\", normalize=True)\n",
    "\n",
    "print(f\"\\nTRAINING COMPLETE! Time: {(time.time()-start_time)/60:.2f} min\")\n",
    "print(f\"Final G Loss: {g_losses[-1]:.4f} | D Loss: {d_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'generator': generator.state_dict(),\n",
    "    'discriminator': discriminator.state_dict(),\n",
    "    'g_losses': g_losses,\n",
    "    'd_losses': d_losses,\n",
    "    'student_name': STUDENT_NAME,\n",
    "    'student_id': STUDENT_ID\n",
    "}, 'checkpoints/gan_checkpoint.pth')\n",
    "print(\"✓ Model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
